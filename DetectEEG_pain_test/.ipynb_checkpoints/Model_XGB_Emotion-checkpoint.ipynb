{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51225b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from scipy import stats\n",
    "import shap\n",
    "import seaborn as sns\n",
    "\n",
    "def SHAP(bst, X_train_df):\n",
    "    # SHAP値を計算\n",
    "    explainer = shap.TreeExplainer(bst)\n",
    "    shap_values = explainer.shap_values(X_train_df)\n",
    "    \n",
    "    # SHAP値をプロット\n",
    "    shap.summary_plot(shap_values, X_train_df, max_display=X_train_df.shape[1])\n",
    "    return shap_values\n",
    "\n",
    "def BFI(bst):\n",
    "    # ビルトインのフィーチャーインポータンスを取得\n",
    "    feature_importances = bst.get_score(importance_type='weight')\n",
    "\n",
    "    # 特徴量の名前とインポータンスをプリント\n",
    "    for key, value in feature_importances.items():\n",
    "        print(f\"Feature: {key}, Importance: {value}\")\n",
    "\n",
    "    # フィーチャーインポータンスをプロット\n",
    "    xgb.plot_importance(bst)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def XGBoost(X, y):\n",
    "    # データを訓練用とテスト用に分割\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # 訓練データをさらに訓練用と検証用に分割\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=0)\n",
    "\n",
    "    # モデルのパラメータを設定(CPU)\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'eta': 0.1,\n",
    "        'max_depth': 4,\n",
    "        'seed': 0\n",
    "    }\n",
    "    \n",
    "    \"\"\"   # モデルのパラメータを設定(GPU)\n",
    "    params = {\n",
    "        'objective': 'multi:softmax',\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'num_class' : 4,\n",
    "        'eta': 0.1,\n",
    "        'max_depth': 12,\n",
    "        'seed': 0,\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'predictor': 'gpu_predictor'\n",
    "    }\"\"\"\n",
    "\n",
    "    # データをpandas.DataFrame形式で保存\n",
    "    X_train_df = pd.DataFrame(X_train, columns=column_names)\n",
    "\n",
    "    # 訓練データと検証データをXGBoostのDMatrix形式に変換\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    # 訓練データと検証データのセットをリストに格納\n",
    "    evals = [(dtrain, 'train'), (dval, 'eval')]\n",
    "\n",
    "    # モデルを訓練\n",
    "    bst = xgb.train(params, dtrain, num_boost_round=10000, evals=evals, early_stopping_rounds=100)\n",
    "\n",
    "    # テストデータをDMatrix形式に変換\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "    # 訓練データで予測\n",
    "    y_train_pred = bst.predict(dtrain)\n",
    "\n",
    "    # テストデータで予測\n",
    "    y_pred = bst.predict(dtest)\n",
    "\n",
    "    # 評価\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred.round())\n",
    "    print(f\"Training Accuracy: {train_accuracy*100:.2f}%\")\n",
    "\n",
    "    # 評価\n",
    "    test_accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "    #SHAP(bst, X_train_df)\n",
    "    # SHAP値を計算\n",
    "    explainer = shap.TreeExplainer(bst)\n",
    "    shap_values = explainer.shap_values(X_train_df)\n",
    "    \n",
    "    # SHAP値をプロット\n",
    "    shap.summary_plot(shap_values, X_train_df, max_display=X_train_df.shape[1])\n",
    "    \n",
    "    #BFI(bst)\n",
    "    return shap_values, y_train_pred, X_train_df, explainer\n",
    "\n",
    "def normalize_per_state(df, start, end):\n",
    "    scaler = StandardScaler()\n",
    "    df.iloc[start:end, :] = scaler.fit_transform(df.iloc[start:end, :])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce7305",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = 0 #rawデータならば１、Bandなら０,\n",
    "\n",
    "# 1秒ごとのデータに分割\n",
    "n_samples_per_second = 256  # 256Hzのサンプリングレート\n",
    "total_seconds = 10  # 全体の秒数\n",
    "\n",
    "# データの読み込み\n",
    "if(raw):\n",
    "    df = pd.read_csv('Raw.csv')\n",
    "    #df = pd.read_csv('Raw_ICA.csv')\n",
    "else:\n",
    "    #df = pd.read_csv('Band.csv')\n",
    "    df = pd.read_csv('emotion.csv')\n",
    "\n",
    "\n",
    "# チャンネルごとに正規化\n",
    "#scaler = StandardScaler()\n",
    "#for column in df.columns[:-1]:  # 'State'列を除くすべての列\n",
    "#    df[column] = scaler.fit_transform(df[column].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a820ba3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Hzごと\n",
    "# 特徴量と目標変数を抽出する\n",
    "X = df.drop('State', axis=1)  # 'State'以外の列すべてを特徴量とします\n",
    "y = df['State']  # 'State'を目標変数とします\n",
    "\n",
    "# 列名のリストを定義\n",
    "column_names = ['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4']\n",
    "#XGBoost\n",
    "#XGBoost(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd3d21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# 訓練データをさらに訓練用と検証用に分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.3, random_state=0)\n",
    "# モデルのパラメータを設定(CPU)\n",
    "\n",
    "\"\"\"\n",
    "params = {\n",
    "'objective': 'binary:logistic',\n",
    "'eval_metric': 'logloss',\n",
    "'eta': 0.1,\n",
    "'max_depth': 4,\n",
    "'seed': 0\n",
    "}\n",
    "      \n",
    "\"\"\"\n",
    "# モデルのパラメータを設定(GPU)\n",
    "params = {\n",
    "'objective': 'multi:softmax',\n",
    "'eval_metric': 'mlogloss',\n",
    "'num_class' : 4,\n",
    "'eta': 0.1,\n",
    "'max_depth': 12,\n",
    "'seed': 0,\n",
    "'tree_method': 'gpu_hist',\n",
    "'predictor': 'gpu_predictor'\n",
    "}\n",
    "\n",
    "# データをpandas.DataFrame形式で保存\n",
    "X_train_df = pd.DataFrame(X_train, columns=column_names)\n",
    "\n",
    "# 訓練データと検証データをXGBoostのDMatrix形式に変換\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# 訓練データと検証データのセットをリストに格納\n",
    "evals = [(dtrain, 'train'), (dval, 'eval')]\n",
    "\n",
    "# モデルを訓練\n",
    "bst = xgb.train(params, dtrain, num_boost_round=10000, evals=evals, early_stopping_rounds=100)\n",
    "\n",
    "# テストデータをDMatrix形式に変換\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "# 訓練データで予測\n",
    "y_train_pred = bst.predict(dtrain)\n",
    "\n",
    "# テストデータで予測\n",
    "y_pred = bst.predict(dtest)\n",
    "\n",
    "# 評価\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred.round())\n",
    "print(f\"Training Accuracy: {train_accuracy*100:.2f}%\")\n",
    "\n",
    "# 評価\n",
    "test_accuracy = accuracy_score(y_test, y_pred.round())\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8979f0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAP(bst, X_train_df)\n",
    "# SHAP値を計算 (バッチ処理)\n",
    "explainer = shap.TreeExplainer(bst)\n",
    "batch_size = 64  # バッチサイズの設定\n",
    "shap_values = []\n",
    "\n",
    "y_train_df = pd.DataFrame(y_train, columns=column_names)\n",
    "# バッチごとにSHAP値を計算\n",
    "\"\"\"\n",
    "for i in range(0, X_train_df.shape[0], batch_size): #X_train_df.shape[0]\n",
    "    batch_start = i\n",
    "    batch_end = min(i + batch_size, X_train_df.shape[0])\n",
    "    batch = X_train_df.iloc[batch_start:batch_end]\n",
    "    batch_y = y_train_df.iloc[batch_start:batch_end]\n",
    "    #print(batch.shape)\n",
    "    shap_values.append(explainer.shap_values(batch,batch_y,tree_limit=2,check_additivity=False))\n",
    "\"\"\"\n",
    "shap_values = explainer.shap_values(X,y,tree_limit=5,check_additivity=False)\n",
    "#一つのリストに結合\n",
    "#shap_values = np.concatenate(shap_values, axis=0)\n",
    "    \n",
    "# SHAP値をプロット\n",
    "#shap.summary_plot(shap_values, X_train_df, max_display=X_train_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad44d47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[2], X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116395a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X100 = shap.utils.sample(X, 100)\n",
    "explainer = shap.TreeExplainer(bst,X100)\n",
    "shap = explainer(X)\n",
    "shap.plots.waterfall(shap[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ef4173",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_label = 4\n",
    "\n",
    "#データフレームに変換\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "y_test_df = pd.DataFrame(y_test, columns = [\"State\"])\n",
    "y_train_df = pd.DataFrame(y_train, columns = [\"State\"])\n",
    "\n",
    "#該当する目的変数を持ったインデックスを格納するリスト\n",
    "DataIndex = []\n",
    "# ↑に対応するtrainデータのラベルインデックス\n",
    "PredictedLabel_index = []\n",
    "# ラベルごとのSHAP値\n",
    "SHAP_EachLabel = []\n",
    "\n",
    "for i in range(count_label):\n",
    "    DataIndex.append(list(y_train_df[y_train_df[\"State\"]==i].index))\n",
    "    PredictedLabel_index.append(X_train.drop(DataIndex[i]))\n",
    "    SHAP_EachLabel.append(explainer.shap_values(PredictedLabel_index[i]))\n",
    "\n",
    "#各ｃｈの電圧値とSHAP値の線形グラフ\n",
    "#shap.dependence_plot(ind = \"O2\", shap_values=shap_values_0_train, features=X_train_0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550e5aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#各ｃｈの電圧値とSHAP値の相関係数\n",
    "# 空のデータフレームを作成\n",
    "correlation_df = pd.DataFrame(columns=['feature', 'correlation_0', 'correlation_1', 'correlation_2', 'correlation_3'])\n",
    "data = []\n",
    "\n",
    "# すべての特徴についてループ\n",
    "for feature in X_train.columns:\n",
    "    # 分類結果が0のときのSHAP値と特徴量の値を取得\n",
    "    shap_values_0 = shap_values_0_train[:, X_train_0.columns.get_loc(feature)]\n",
    "    feature_values_0 = X_train_0[feature]\n",
    "    # 分類結果が1のときのSHAP値と特徴量の値を取得\n",
    "    shap_values_1 = shap_values_1_train[:, X_train_1.columns.get_loc(feature)]\n",
    "    feature_values_1 = X_train_1[feature]\n",
    "    \n",
    "    # NumPyのcorrcoef関数を用いて相関係数を計算\n",
    "    correlation_coefficient_0 = np.corrcoef(shap_values_0, feature_values_0)[0, 1]\n",
    "    correlation_coefficient_1 = np.corrcoef(shap_values_1, feature_values_1)[0, 1]\n",
    "    \n",
    "    # リストに相関係数を追加\n",
    "    data.append({'feature': feature, \n",
    "                 'correlation_0': correlation_coefficient_0,\n",
    "                 'correlation_1': correlation_coefficient_1})\n",
    "\n",
    "# pandas.concatを用いてデータフレームを作成\n",
    "correlation_df = pd.concat([correlation_df, pd.DataFrame(data)], ignore_index=True).T\n",
    "\n",
    "# データフレームを表示\n",
    "correlation_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a46e85d",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "#１秒ごとに分割\n",
    "# ラベルの作成（5秒閉じ、5秒開け）\n",
    "labels_close = [0] * 5 *64 \n",
    "labels_open = [1] * 5 * 64\n",
    "labels = labels_close + labels_open\n",
    "\n",
    "#labels = df.iloc[:, -1]\n",
    "\n",
    "#14chデータ\n",
    "n_samples_per_second = 4\n",
    "total_seconds = 10  # 全体の秒数\n",
    "#total_seconds = 3242  # 全体の秒数\n",
    "\n",
    "# データとラベルを1秒ごとに分割\n",
    "#X = np.array([df.iloc[i*n_samples_per_second:(i+1)*n_samples_per_second, :-1].values for i in range(total_seconds)])\n",
    "\n",
    "X = np.array([df.iloc[i*n_samples_per_second:(i+1)*n_samples_per_second, :-1].values for i in range(total_seconds*64)])\n",
    "#labels = np.array([stats.mode(y[i*n_samples_per_second:(i+1)*n_samples_per_second])[0][0] for i in range(total_seconds*64)])\n",
    "\n",
    "\n",
    "# 1秒ごとのデータの平均を取得\n",
    "X = X.mean(axis=1)\n",
    "\n",
    "#XGBoost\n",
    "XGBoost(X, labels)\n",
    "\n",
    "#plot\n",
    "#plot_importance(raw, model1)\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
